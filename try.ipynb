{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import utils\n",
    "from basic_fcn import *\n",
    "from resnet18 import *\n",
    "from dataloader import *\n",
    "from utils import *\n",
    "from utils import *\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm, tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CityScapesDataset(csv_file='train.csv', transforms=transforms.RandomCrop(512,512))\n",
    "val_dataset = CityScapesDataset(csv_file='val.csv')\n",
    "test_dataset = CityScapesDataset(csv_file='test.csv')\n",
    "train_loader = DataLoader(dataset=train_dataset,\n",
    "                          batch_size=5,\n",
    "                          num_workers=0,\n",
    "                          shuffle=False, \n",
    "                         )\n",
    "val_loader = DataLoader(dataset=val_dataset,\n",
    "                          batch_size=2,\n",
    "                          num_workers=0,\n",
    "                          shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset,\n",
    "                          batch_size=1,\n",
    "                          num_workers=0,\n",
    "                          shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "        torch.nn.init.xavier_uniform_(m.weight.data)\n",
    "#         torch.nn.init.xavier_uniform(m.bias.data, 0)\n",
    "        nn.init.constant_(m.bias, 0)\n",
    "        \n",
    "n_class = 34\n",
    "epochs = 2\n",
    "criterion = nn.CrossEntropyLoss() # Choose an appropriate loss function from https://pytorch.org/docs/stable/_modules/torch/nn/modules/loss.html\n",
    "# model = Resnet18(n_class=n_class)\n",
    "model = FCN(n_class=n_class)\n",
    "model.apply(init_weights)\n",
    "# model.load_state_dict(torch.load('./saved_models/resnet18_1'))\n",
    "optimizer = optim.Adam(model.parameters(), lr=5e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'epochs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-49a2d1c8eeee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[1;31m#     val(0)  # show the accuracy before training\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 144\u001b[1;33m     \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-4-49a2d1c8eeee>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mval_losses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[0mrunning_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'epochs' is not defined"
     ]
    }
   ],
   "source": [
    "use_gpu = torch.cuda.is_available()\n",
    "if use_gpu:\n",
    "    print(\"GPU is available\")\n",
    "    model = model.cuda()\n",
    "    \n",
    "def train():\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        ts = time.time()\n",
    "        for iter, (X, Y) in tqdm(enumerate(train_loader), desc =\"Iteration num: \"): # X=input_images, tar=one-hot labelled, y=segmentated\n",
    "            optimizer.zero_grad()\n",
    "            Y = Y.long()\n",
    "            if use_gpu:\n",
    "                inputs = X.cuda() # Move your inputs onto the gpu\n",
    "                labels = Y.cuda() # Move your labels onto the gpu\n",
    "                inputs.required_grad = False\n",
    "                labels.required_grad = False\n",
    "\n",
    "            else:\n",
    "                inputs, labels =  X, Y # Unpack variables into inputs and labels\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            break \n",
    "\n",
    "            if iter % 10 == 0:\n",
    "                print(\"epoch{}, iter{}, loss: {}\".format(epoch, iter, loss.item()))\n",
    "        \n",
    "        print(\"Finish epoch {}, time elapsed {}\".format(epoch, time.time() - ts))\n",
    "#         torch.save(model.state_dict(), \"./saved_models/resnet18_\"+str(epoch))\n",
    "        \n",
    "#         train_losses.append(running_loss/len(train_loader))\n",
    "        train_losses.append(running_loss/5)\n",
    "#         val_loss = val(epoch)\n",
    "        torch.cuda.empty_cache()\n",
    "#         val_losses.append(val_loss)\n",
    "        \n",
    "        model.train()\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "    x = [i for i in range(epochs)]\n",
    "    plt.title(\"Plot showing training and validation loss against number of epochs\")\n",
    "    plt.xlabel(\"Number of epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.plot(x, train_losses, color='r', label='training loss')\n",
    "#     plt.plot(x, val_losses, color = 'b', label = 'validation loss')\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.savefig(\"./results/resnet18-loss.png\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def val(epoch):\n",
    "    model.eval()\n",
    "\n",
    "    #Complete this function - Calculate loss, accuracy and IoU for every epoch\n",
    "    # Make sure to include a softmax after the output from your model\n",
    "    # Evaluate\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    running_loss = 0.0\n",
    "    final = np.ones((1,19))\n",
    "    for iter, (inputs, labels) in tqdm(enumerate(val_loader)):\n",
    "        inputs, labels = inputs, labels.long()\n",
    "        if use_gpu:\n",
    "            inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        out = iou(outputs, labels)\n",
    "        #print(out)\n",
    "        final = np.vstack((final, out))\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        \n",
    "        outputs = outputs.cpu()\n",
    "        outputs = outputs.detach().numpy()\n",
    "        labels = labels.cpu()\n",
    "        labels = labels.detach().numpy()\n",
    "\n",
    "        predict = np.argmax(outputs, axis = 1)\n",
    "        correct = np.where(predict == labels, 1, 0).sum()\n",
    "        total = predict.size\n",
    "\n",
    "    final = np.mean(final[1:,], axis = 0)\n",
    "    avg_final = np.mean(final)         \n",
    "\n",
    "    \n",
    "    print('Epoch : %d Validation Pixel Acc : %.3f' % (epoch + 1, 100.*correct/total))\n",
    "    print('--------------------------------------------------------------')\n",
    "    print('Epoch : %d Validation Avg IOU : %.3f' % (epoch + 1, avg_final))\n",
    "    print('--------------------------------------------------------------')\n",
    "    print('Epoch : %d Each class IOU : %.3f' % (epoch + 1, final))\n",
    "\n",
    "    return (running_loss/len(val_loader))\n",
    "\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    final = np.ones((1,19))  \n",
    "    #Complete this function - Calculate loss, accuracy and IoU for every epoch\n",
    "    # Make sure to include a softmax after the output from your model\n",
    "    # Evaluate\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for iter, (X, Y) in tqdm(enumerate(val_loader)):\n",
    "        inputs, labels = X, Y.long()\n",
    "        if use_gpu:\n",
    "            inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        out = iou(outputs, labels)\n",
    "        #print(out)\n",
    "        final = np.vstack((final, out))        \n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels.data).cpu().sum()\n",
    "        \n",
    "    final = np.mean(final[1:,], axis = 0)\n",
    "    avg_final = np.mean(final)\n",
    "          \n",
    "        \n",
    "    print('Epoch : %d Test Pixel Acc : %.3f' % (epoch + 1, 100.*correct/total))\n",
    "    print('--------------------------------------------------------------')\n",
    "    print('Epoch : %d Test Avg IOU : %.3f' % (epoch + 1, avg_final))\n",
    "    print('--------------------------------------------------------------')\n",
    "    print('Epoch : %d Each class IOU : %.3f' % (epoch + 1, final))\n",
    "    \n",
    "\n",
    "    #Complete this function - Calculate accuracy and IoU \n",
    "    # Make sure to include a softmax after the output from your model\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "#     val(0)  # show the accuracy before training\n",
    "    train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = 0\n",
    "for iter, (X, tar, Y) in enumerate(train_loader):\n",
    "    print(iter,\": \", time.time()-tic)\n",
    "    tic = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
